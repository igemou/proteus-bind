{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmRdPV_mE5OY",
        "outputId": "e571044f-e6cc-42d9-f16e-67c62e33179a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec  9 22:29:37 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Ensure you are connected to GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PrismNet dependencies\n",
        "!pip install torch torchvision torchaudio --quiet\n",
        "!pip install pandas numpy scikit-learn matplotlib seaborn --quiet\n",
        "!pip install biopython --quiet\n",
        "!pip install tensorboardX --quiet"
      ],
      "metadata": {
        "id": "gWlmn81AFD6q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FIRST MOUNT GOOGLE DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaxToYIAFD-H",
        "outputId": "a2181291-70cc-4a29-d369-27db617011c6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/PrismNet_files/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkUOCKK8FEBa",
        "outputId": "949410c8-c92c-4a54-8eae-17cbbd3bb554"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\t motif_construct    README.md\t\t setup.py\n",
            "exp\t prismnet\t    requirements.txt\t tools\n",
            "LICENSE  prismnet.egg-info  run_prismnet_all.sh  train.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Change this path to where your PrismNet folder is in Drive\n",
        "os.chdir(\"/content/drive/MyDrive/PrismNet_files\")\n",
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWCRqrhkFEDN",
        "outputId": "74f14554-18ea-47c0-ac71-e650c7f88c0e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PrismNet_files\n",
            "data\t motif_construct    README.md\t\t setup.py\n",
            "exp\t prismnet\t    requirements.txt\t tools\n",
            "LICENSE  prismnet.egg-info  run_prismnet_all.sh  train.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import os\n",
        "\n",
        "# List of all six proteins\n",
        "proteins = [\n",
        "    'PCBP1_K562',\n",
        "    'SRSF9_HepG2',\n",
        "    'TRA2A_K562',\n",
        "    'HNRNPC_Hela',\n",
        "    'PCBP2_HepG2',\n",
        "    'TIA1_Hela'\n",
        "]\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/PrismNet_files/data/clip_data/'\n",
        "\n",
        "for p in proteins:\n",
        "    file_path = os.path.join(data_dir, f'{p}.h5')\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"{p}.h5 not found!\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nProtein: {p}\")\n",
        "    print(\"File size:\", os.path.getsize(file_path)/1e6, \"MB\")\n",
        "\n",
        "    with h5py.File(file_path, 'r') as f:\n",
        "        print(\"Datasets:\", list(f.keys()))\n",
        "        for k in f.keys():\n",
        "            print(f\"{k} shape: {f[k].shape}, dtype: {f[k].dtype}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-IWkfrpQfow",
        "outputId": "79d1e155-1c22-4989-f74b-2abe282c42d4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Protein: PCBP1_K562\n",
            "File size: 4.347325 MB\n",
            "Datasets: ['X_test', 'X_train', 'Y_test', 'Y_train']\n",
            "X_test shape: (3000, 5, 101), dtype: float32\n",
            "X_train shape: (12000, 5, 101), dtype: float32\n",
            "Y_test shape: (3000, 1), dtype: int32\n",
            "Y_train shape: (12000, 1), dtype: int32\n",
            "\n",
            "Protein: SRSF9_HepG2\n",
            "File size: 4.235208 MB\n",
            "Datasets: ['X_test', 'X_train', 'Y_test', 'Y_train']\n",
            "X_test shape: (3000, 5, 101), dtype: float32\n",
            "X_train shape: (12002, 5, 101), dtype: float32\n",
            "Y_test shape: (3000, 1), dtype: int32\n",
            "Y_train shape: (12002, 1), dtype: int32\n",
            "\n",
            "Protein: TRA2A_K562\n",
            "File size: 4.324073 MB\n",
            "Datasets: ['X_test', 'X_train', 'Y_test', 'Y_train']\n",
            "X_test shape: (3000, 5, 101), dtype: float32\n",
            "X_train shape: (12002, 5, 101), dtype: float32\n",
            "Y_test shape: (3000, 1), dtype: int32\n",
            "Y_train shape: (12002, 1), dtype: int32\n",
            "\n",
            "Protein: HNRNPC_Hela\n",
            "File size: 4.31344 MB\n",
            "Datasets: ['X_test', 'X_train', 'Y_test', 'Y_train']\n",
            "X_test shape: (3000, 5, 101), dtype: float32\n",
            "X_train shape: (12002, 5, 101), dtype: float32\n",
            "Y_test shape: (3000, 1), dtype: int32\n",
            "Y_train shape: (12002, 1), dtype: int32\n",
            "\n",
            "Protein: PCBP2_HepG2\n",
            "File size: 4.267376 MB\n",
            "Datasets: ['X_test', 'X_train', 'Y_test', 'Y_train']\n",
            "X_test shape: (3000, 5, 101), dtype: float32\n",
            "X_train shape: (12002, 5, 101), dtype: float32\n",
            "Y_test shape: (3000, 1), dtype: int32\n",
            "Y_train shape: (12002, 1), dtype: int32\n",
            "\n",
            "Protein: TIA1_Hela\n",
            "File size: 4.285813 MB\n",
            "Datasets: ['X_test', 'X_train', 'Y_test', 'Y_train']\n",
            "X_test shape: (3000, 5, 101), dtype: float32\n",
            "X_train shape: (12002, 5, 101), dtype: float32\n",
            "Y_test shape: (3000, 1), dtype: int32\n",
            "Y_train shape: (12002, 1), dtype: int32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PCBP1_K562\n",
        "!python -u /content/drive/MyDrive/PrismNet_files/tools/main.py \\\n",
        "    --train --eval \\\n",
        "    --lr 0.001 \\\n",
        "    --data_dir /content/drive/MyDrive/PrismNet_files/data/clip_data/ \\\n",
        "    --p_name PCBP1_K562 \\\n",
        "    --out_dir /content/drive/MyDrive/PrismNet_files/exp/prismnet \\\n",
        "    --exp_name prismnet \\\n",
        "    --batch_size 32 \\\n",
        "    --workers 2 \\\n",
        "    --nepochs 5 \\\n",
        "    --pos_weight 2 \\\n",
        "    --weight_decay 1e-6 \\\n",
        "    --early_stopping 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reAU4_5aQuOL",
        "outputId": "e066a3f8-b949-414e-fae7-fd1df7ff407f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='/content/drive/MyDrive/PrismNet_files/data/clip_data/', exp_name='prismnet', p_name='PCBP1_K562', out_dir='/content/drive/MyDrive/PrismNet_files/exp/prismnet', mode='pu', infer_file='', arch='PrismNet', lr_scheduler='warmup', lr=0.001, batch_size=32, nepochs=5, pos_weight=2, weight_decay=1e-06, early_stopping=20, load_best=False, eval=True, train=True, infer=False, infer_test=False, eval_test=False, saliency=False, saliency_img=False, har=False, tfboard=False, no_cuda=False, workers=2, log_interval=100, seed=1024)\n",
            "Network Arch: PrismNet\n",
            "===========================\n",
            "Total params: 58189\n",
            "Trainable params: 58189\n",
            "Non-trainable params: 0\n",
            "===========================\n",
            "train: [0 1] [8000 4000]\n",
            "test: [0 1] [2000 1000]\n",
            "train: [0 1] [8000 4000]\n",
            "test: [0 1] [2000 1000]\n",
            "Train set: 12000\n",
            "Test  set: 3000\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mPCBP1_K562 \t Train Epoch: 1     avg.loss: 0.6885 Acc: 0.75%, AUC: 0.8264 lr: 0.002400\u001b[0m\n",
            "\u001b[1m\u001b[31mPCBP1_K562 \t Test  Epoch: 1     avg.loss: 0.6720 Acc: 0.72%, AUC: 0.8621 (0.8621)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mPCBP1_K562 \t Train Epoch: 2     avg.loss: 0.6380 Acc: 0.78%, AUC: 0.8612 lr: 0.003800\u001b[0m\n",
            "\u001b[1m\u001b[31mPCBP1_K562 \t Test  Epoch: 2     avg.loss: 1.1970 Acc: 0.44%, AUC: 0.8715 (0.8715)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mPCBP1_K562 \t Train Epoch: 3     avg.loss: 0.6091 Acc: 0.79%, AUC: 0.8741 lr: 0.005200\u001b[0m\n",
            "\u001b[1m\u001b[31mPCBP1_K562 \t Test  Epoch: 3     avg.loss: 0.5958 Acc: 0.76%, AUC: 0.8940 (0.8940)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mPCBP1_K562 \t Train Epoch: 4     avg.loss: 0.5884 Acc: 0.80%, AUC: 0.8879 lr: 0.006600\u001b[0m\n",
            "\u001b[1m\u001b[31mPCBP1_K562 \t Test  Epoch: 4     avg.loss: 0.8561 Acc: 0.59%, AUC: 0.8978 (0.8978)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mPCBP1_K562 \t Train Epoch: 5     avg.loss: 0.5725 Acc: 0.80%, AUC: 0.8949 lr: 0.008000\u001b[0m\n",
            "\u001b[1m\u001b[31mPCBP1_K562 \t Test  Epoch: 5     avg.loss: 0.5556 Acc: 0.84%, AUC: 0.9019 (0.9019)\u001b[0m\n",
            "PCBP1_K562 auc: 0.9019 acc: 0.8400\n",
            "Loading model: /content/drive/MyDrive/PrismNet_files/exp/prismnet/out/models/PCBP1_K562_PrismNet_pu_best.pth\n",
            "train: [0 1] [8000 4000]\n",
            "test: [0 1] [2000 1000]\n",
            "Test  set: 3000\n",
            "> eval PCBP1_K562 auc: 0.9019 acc: 0.8400\n",
            "Evaluation file: /content/drive/MyDrive/PrismNet_files/exp/prismnet/out/evals/PCBP1_K562_PrismNet_pu.metrics\n",
            "Prediction file: /content/drive/MyDrive/PrismNet_files/exp/prismnet/out/evals/PCBP1_K562_PrismNet_pu.probs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SRSF9_HepG2\n",
        "!python -u /content/drive/MyDrive/PrismNet_files/tools/main.py \\\n",
        "    --train --eval \\\n",
        "    --lr 0.001 \\\n",
        "    --data_dir /content/drive/MyDrive/PrismNet_files/data/clip_data/ \\\n",
        "    --p_name SRSF9_HepG2 \\\n",
        "    --out_dir /content/drive/MyDrive/PrismNet_files/exp/prismnet \\\n",
        "    --exp_name prismnet \\\n",
        "    --batch_size 32 \\\n",
        "    --workers 2 \\\n",
        "    --nepochs 5 \\\n",
        "    --pos_weight 2 \\\n",
        "    --weight_decay 1e-6 \\\n",
        "    --early_stopping 20\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzLrcHFOQyHV",
        "outputId": "1536421f-b09b-44e4-cc59-e3d886c92ede"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='/content/drive/MyDrive/PrismNet_files/data/clip_data/', exp_name='prismnet', p_name='SRSF9_HepG2', out_dir='/content/drive/MyDrive/PrismNet_files/exp/prismnet', mode='pu', infer_file='', arch='PrismNet', lr_scheduler='warmup', lr=0.001, batch_size=32, nepochs=5, pos_weight=2, weight_decay=1e-06, early_stopping=20, load_best=False, eval=True, train=True, infer=False, infer_test=False, eval_test=False, saliency=False, saliency_img=False, har=False, tfboard=False, no_cuda=False, workers=2, log_interval=100, seed=1024)\n",
            "Network Arch: PrismNet\n",
            "===========================\n",
            "Total params: 58189\n",
            "Trainable params: 58189\n",
            "Non-trainable params: 0\n",
            "===========================\n",
            "train: [0 1] [8002 4000]\n",
            "test: [0 1] [2000 1000]\n",
            "train: [0 1] [8002 4000]\n",
            "test: [0 1] [2000 1000]\n",
            "Train set: 12002\n",
            "Test  set: 3000\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mSRSF9_HepG2 \t Train Epoch: 1     avg.loss: 0.8096 Acc: 0.66%, AUC: 0.7361 lr: 0.002400\u001b[0m\n",
            "\u001b[1m\u001b[31mSRSF9_HepG2 \t Test  Epoch: 1     avg.loss: 0.8184 Acc: 0.72%, AUC: 0.7529 (0.7529)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mSRSF9_HepG2 \t Train Epoch: 2     avg.loss: 0.7678 Acc: 0.70%, AUC: 0.7794 lr: 0.003800\u001b[0m\n",
            "\u001b[1m\u001b[31mSRSF9_HepG2 \t Test  Epoch: 2     avg.loss: 1.1960 Acc: 0.71%, AUC: 0.7757 (0.7757)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/PrismNet_files/prismnet/utils/metrics.py:169: RuntimeWarning: Mean of empty slice\n",
            "  mean = [np.nanmean(correct), np.nanmean(auc_roc), np.nanmean(auc_pr),tp, tn, fp, fn]\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/lib/_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
            "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mSRSF9_HepG2 \t Train Epoch: 3     avg.loss: 0.7580 Acc: 0.71%, AUC: nan lr: 0.005200\u001b[0m\n",
            "\u001b[1m\u001b[31mSRSF9_HepG2 \t Test  Epoch: 3     avg.loss: 0.9289 Acc: 0.75%, AUC: 0.7976 (0.7976)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/PrismNet_files/prismnet/utils/metrics.py:169: RuntimeWarning: Mean of empty slice\n",
            "  mean = [np.nanmean(correct), np.nanmean(auc_roc), np.nanmean(auc_pr),tp, tn, fp, fn]\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/lib/_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
            "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mSRSF9_HepG2 \t Train Epoch: 4     avg.loss: 0.7365 Acc: 0.72%, AUC: nan lr: 0.006600\u001b[0m\n",
            "\u001b[1m\u001b[31mSRSF9_HepG2 \t Test  Epoch: 4     avg.loss: 0.7969 Acc: 0.66%, AUC: 0.7982 (0.7982)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mSRSF9_HepG2 \t Train Epoch: 5     avg.loss: 0.7193 Acc: 0.73%, AUC: 0.8140 lr: 0.008000\u001b[0m\n",
            "\u001b[1m\u001b[31mSRSF9_HepG2 \t Test  Epoch: 5     avg.loss: 0.7503 Acc: 0.67%, AUC: 0.8047 (0.8047)\u001b[0m\n",
            "SRSF9_HepG2 auc: 0.8047 acc: 0.6747\n",
            "Loading model: /content/drive/MyDrive/PrismNet_files/exp/prismnet/out/models/SRSF9_HepG2_PrismNet_pu_best.pth\n",
            "train: [0 1] [8002 4000]\n",
            "test: [0 1] [2000 1000]\n",
            "Test  set: 3000\n",
            "> eval SRSF9_HepG2 auc: 0.8047 acc: 0.6747\n",
            "Evaluation file: /content/drive/MyDrive/PrismNet_files/exp/prismnet/out/evals/SRSF9_HepG2_PrismNet_pu.metrics\n",
            "Prediction file: /content/drive/MyDrive/PrismNet_files/exp/prismnet/out/evals/SRSF9_HepG2_PrismNet_pu.probs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRA2A_K562\n",
        "!python -u /content/drive/MyDrive/PrismNet_files/tools/main.py \\\n",
        "    --train --eval \\\n",
        "    --lr 0.001 \\\n",
        "    --data_dir /content/drive/MyDrive/PrismNet_files/data/clip_data/ \\\n",
        "    --p_name TRA2A_K562 \\\n",
        "    --out_dir /content/drive/MyDrive/PrismNet_files/exp/prismnet \\\n",
        "    --exp_name prismnet \\\n",
        "    --batch_size 32 \\\n",
        "    --workers 2 \\\n",
        "    --nepochs 5 \\\n",
        "    --pos_weight 2 \\\n",
        "    --weight_decay 1e-6 \\\n",
        "    --early_stopping 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKs94VSZQzeo",
        "outputId": "ed2041a7-02d7-4fb0-87ff-4e6d974680ad"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='/content/drive/MyDrive/PrismNet_files/data/clip_data/', exp_name='prismnet', p_name='TRA2A_K562', out_dir='/content/drive/MyDrive/PrismNet_files/exp/prismnet', mode='pu', infer_file='', arch='PrismNet', lr_scheduler='warmup', lr=0.001, batch_size=32, nepochs=5, pos_weight=2, weight_decay=1e-06, early_stopping=20, load_best=False, eval=True, train=True, infer=False, infer_test=False, eval_test=False, saliency=False, saliency_img=False, har=False, tfboard=False, no_cuda=False, workers=2, log_interval=100, seed=1024)\n",
            "Network Arch: PrismNet\n",
            "===========================\n",
            "Total params: 58189\n",
            "Trainable params: 58189\n",
            "Non-trainable params: 0\n",
            "===========================\n",
            "train: [0 1] [8002 4000]\n",
            "test: [0 1] [2000 1000]\n",
            "train: [0 1] [8002 4000]\n",
            "test: [0 1] [2000 1000]\n",
            "Train set: 12002\n",
            "Test  set: 3000\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mTRA2A_K562 \t Train Epoch: 1     avg.loss: 0.7423 Acc: 0.72%, AUC: 0.7920 lr: 0.002400\u001b[0m\n",
            "\u001b[1m\u001b[31mTRA2A_K562 \t Test  Epoch: 1     avg.loss: 0.8631 Acc: 0.64%, AUC: 0.8254 (0.8254)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mTRA2A_K562 \t Train Epoch: 2     avg.loss: 0.6829 Acc: 0.75%, AUC: 0.8365 lr: 0.003800\u001b[0m\n",
            "\u001b[1m\u001b[31mTRA2A_K562 \t Test  Epoch: 2     avg.loss: 0.6615 Acc: 0.81%, AUC: 0.8641 (0.8641)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/PrismNet_files/prismnet/utils/metrics.py:169: RuntimeWarning: Mean of empty slice\n",
            "  mean = [np.nanmean(correct), np.nanmean(auc_roc), np.nanmean(auc_pr),tp, tn, fp, fn]\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/lib/_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
            "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mTRA2A_K562 \t Train Epoch: 3     avg.loss: 0.6648 Acc: 0.76%, AUC: nan lr: 0.005200\u001b[0m\n",
            "\u001b[1m\u001b[31mTRA2A_K562 \t Test  Epoch: 3     avg.loss: 0.6359 Acc: 0.73%, AUC: 0.8726 (0.8726)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/PrismNet_files/prismnet/utils/metrics.py:169: RuntimeWarning: Mean of empty slice\n",
            "  mean = [np.nanmean(correct), np.nanmean(auc_roc), np.nanmean(auc_pr),tp, tn, fp, fn]\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/lib/_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
            "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mTRA2A_K562 \t Train Epoch: 4     avg.loss: 0.6423 Acc: 0.77%, AUC: nan lr: 0.006600\u001b[0m\n",
            "\u001b[1m\u001b[31mTRA2A_K562 \t Test  Epoch: 4     avg.loss: 0.6189 Acc: 0.81%, AUC: 0.8741 (0.8741)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mTRA2A_K562 \t Train Epoch: 5     avg.loss: 0.6271 Acc: 0.78%, AUC: 0.8695 lr: 0.008000\u001b[0m\n",
            "\u001b[1m\u001b[32mTRA2A_K562 \t Test  Epoch: 5     avg.loss: 0.7052 Acc: 0.80%, AUC: 0.8661 (0.8741)\u001b[0m\n",
            "TRA2A_K562 auc: 0.8741 acc: 0.8077\n",
            "Loading model: /content/drive/MyDrive/PrismNet_files/exp/prismnet/out/models/TRA2A_K562_PrismNet_pu_best.pth\n",
            "train: [0 1] [8002 4000]\n",
            "test: [0 1] [2000 1000]\n",
            "Test  set: 3000\n",
            "> eval TRA2A_K562 auc: 0.8741 acc: 0.8077\n",
            "Evaluation file: /content/drive/MyDrive/PrismNet_files/exp/prismnet/out/evals/TRA2A_K562_PrismNet_pu.metrics\n",
            "Prediction file: /content/drive/MyDrive/PrismNet_files/exp/prismnet/out/evals/TRA2A_K562_PrismNet_pu.probs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HNRNPC_Hela\n",
        "!python -u /content/drive/MyDrive/PrismNet_files/tools/main.py \\\n",
        "    --train --eval \\\n",
        "    --lr 0.001 \\\n",
        "    --data_dir /content/drive/MyDrive/PrismNet_files/data/clip_data/ \\\n",
        "    --p_name HNRNPC_Hela \\\n",
        "    --out_dir /content/drive/MyDrive/PrismNet_files/exp/prismnet \\\n",
        "    --exp_name prismnet \\\n",
        "    --batch_size 32 \\\n",
        "    --workers 2 \\\n",
        "    --nepochs 5 \\\n",
        "    --pos_weight 2 \\\n",
        "    --weight_decay 1e-6 \\\n",
        "    --early_stopping 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_qtR9aKTD3V",
        "outputId": "507138b4-0ae2-4999-fc73-7fb058118de8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='/content/drive/MyDrive/PrismNet_files/data/clip_data/', exp_name='prismnet', p_name='HNRNPC_Hela', out_dir='/content/drive/MyDrive/PrismNet_files/exp/prismnet', mode='pu', infer_file='', arch='PrismNet', lr_scheduler='warmup', lr=0.001, batch_size=32, nepochs=5, pos_weight=2, weight_decay=1e-06, early_stopping=20, load_best=False, eval=True, train=True, infer=False, infer_test=False, eval_test=False, saliency=False, saliency_img=False, har=False, tfboard=False, no_cuda=False, workers=2, log_interval=100, seed=1024)\n",
            "Network Arch: PrismNet\n",
            "===========================\n",
            "Total params: 58189\n",
            "Trainable params: 58189\n",
            "Non-trainable params: 0\n",
            "===========================\n",
            "train: [0 1] [8002 4000]\n",
            "test: [0 1] [2000 1000]\n",
            "train: [0 1] [8002 4000]\n",
            "test: [0 1] [2000 1000]\n",
            "Train set: 12002\n",
            "Test  set: 3000\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mHNRNPC_Hela \t Train Epoch: 1     avg.loss: 0.5745 Acc: 0.81%, AUC: 0.8906 lr: 0.002400\u001b[0m\n",
            "\u001b[1m\u001b[31mHNRNPC_Hela \t Test  Epoch: 1     avg.loss: 0.6185 Acc: 0.83%, AUC: 0.8986 (0.8986)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mHNRNPC_Hela \t Train Epoch: 2     avg.loss: 0.5418 Acc: 0.83%, AUC: 0.9055 lr: 0.003800\u001b[0m\n",
            "\u001b[1m\u001b[31mHNRNPC_Hela \t Test  Epoch: 2     avg.loss: 0.5428 Acc: 0.81%, AUC: 0.9057 (0.9057)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/PrismNet_files/prismnet/utils/metrics.py:169: RuntimeWarning: Mean of empty slice\n",
            "  mean = [np.nanmean(correct), np.nanmean(auc_roc), np.nanmean(auc_pr),tp, tn, fp, fn]\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/lib/_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
            "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mHNRNPC_Hela \t Train Epoch: 3     avg.loss: 0.5417 Acc: 0.83%, AUC: nan lr: 0.005200\u001b[0m\n",
            "\u001b[1m\u001b[31mHNRNPC_Hela \t Test  Epoch: 3     avg.loss: 0.5229 Acc: 0.83%, AUC: 0.9086 (0.9086)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/PrismNet_files/prismnet/utils/metrics.py:169: RuntimeWarning: Mean of empty slice\n",
            "  mean = [np.nanmean(correct), np.nanmean(auc_roc), np.nanmean(auc_pr),tp, tn, fp, fn]\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/lib/_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
            "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mHNRNPC_Hela \t Train Epoch: 4     avg.loss: 0.5332 Acc: 0.82%, AUC: nan lr: 0.006600\u001b[0m\n",
            "\u001b[1m\u001b[31mHNRNPC_Hela \t Test  Epoch: 4     avg.loss: 0.5573 Acc: 0.80%, AUC: 0.9128 (0.9128)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mHNRNPC_Hela \t Train Epoch: 5     avg.loss: 0.5201 Acc: 0.83%, AUC: 0.9148 lr: 0.008000\u001b[0m\n",
            "\u001b[1m\u001b[32mHNRNPC_Hela \t Test  Epoch: 5     avg.loss: 0.6096 Acc: 0.76%, AUC: 0.9115 (0.9128)\u001b[0m\n",
            "HNRNPC_Hela auc: 0.9128 acc: 0.7973\n",
            "Loading model: /content/drive/MyDrive/PrismNet_files/exp/prismnet/out/models/HNRNPC_Hela_PrismNet_pu_best.pth\n",
            "train: [0 1] [8002 4000]\n",
            "test: [0 1] [2000 1000]\n",
            "Test  set: 3000\n",
            "> eval HNRNPC_Hela auc: 0.9128 acc: 0.7973\n",
            "Evaluation file: /content/drive/MyDrive/PrismNet_files/exp/prismnet/out/evals/HNRNPC_Hela_PrismNet_pu.metrics\n",
            "Prediction file: /content/drive/MyDrive/PrismNet_files/exp/prismnet/out/evals/HNRNPC_Hela_PrismNet_pu.probs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PCBP2_HepG2\n",
        "!python -u /content/drive/MyDrive/PrismNet_files/tools/main.py \\\n",
        "    --train --eval \\\n",
        "    --lr 0.001 \\\n",
        "    --data_dir /content/drive/MyDrive/PrismNet_files/data/clip_data/ \\\n",
        "    --p_name PCBP2_HepG2 \\\n",
        "    --out_dir /content/drive/MyDrive/PrismNet_files/exp/prismnet \\\n",
        "    --exp_name prismnet \\\n",
        "    --batch_size 32 \\\n",
        "    --workers 2 \\\n",
        "    --nepochs 5 \\\n",
        "    --pos_weight 2 \\\n",
        "    --weight_decay 1e-6 \\\n",
        "    --early_stopping 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urehscxWTFPJ",
        "outputId": "d9b7162b-4b1a-49af-da83-92526f356647"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='/content/drive/MyDrive/PrismNet_files/data/clip_data/', exp_name='prismnet', p_name='PCBP2_HepG2', out_dir='/content/drive/MyDrive/PrismNet_files/exp/prismnet', mode='pu', infer_file='', arch='PrismNet', lr_scheduler='warmup', lr=0.001, batch_size=32, nepochs=5, pos_weight=2, weight_decay=1e-06, early_stopping=20, load_best=False, eval=True, train=True, infer=False, infer_test=False, eval_test=False, saliency=False, saliency_img=False, har=False, tfboard=False, no_cuda=False, workers=2, log_interval=100, seed=1024)\n",
            "Network Arch: PrismNet\n",
            "===========================\n",
            "Total params: 58189\n",
            "Trainable params: 58189\n",
            "Non-trainable params: 0\n",
            "===========================\n",
            "train: [0 1] [8002 4000]\n",
            "test: [0 1] [2000 1000]\n",
            "train: [0 1] [8002 4000]\n",
            "test: [0 1] [2000 1000]\n",
            "Train set: 12002\n",
            "Test  set: 3000\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mPCBP2_HepG2 \t Train Epoch: 1     avg.loss: 0.5980 Acc: 0.80%, AUC: 0.8793 lr: 0.002400\u001b[0m\n",
            "\u001b[1m\u001b[31mPCBP2_HepG2 \t Test  Epoch: 1     avg.loss: 0.5411 Acc: 0.81%, AUC: 0.9102 (0.9102)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mPCBP2_HepG2 \t Train Epoch: 2     avg.loss: 0.5482 Acc: 0.83%, AUC: 0.9012 lr: 0.003800\u001b[0m\n",
            "\u001b[1m\u001b[31mPCBP2_HepG2 \t Test  Epoch: 2     avg.loss: 0.4900 Acc: 0.84%, AUC: 0.9135 (0.9135)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/PrismNet_files/prismnet/utils/metrics.py:169: RuntimeWarning: Mean of empty slice\n",
            "  mean = [np.nanmean(correct), np.nanmean(auc_roc), np.nanmean(auc_pr),tp, tn, fp, fn]\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/lib/_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
            "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mPCBP2_HepG2 \t Train Epoch: 3     avg.loss: 0.5517 Acc: 0.83%, AUC: nan lr: 0.005200\u001b[0m\n",
            "\u001b[1m\u001b[32mPCBP2_HepG2 \t Test  Epoch: 3     avg.loss: 0.6951 Acc: 0.84%, AUC: 0.9091 (0.9135)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/PrismNet_files/prismnet/utils/metrics.py:169: RuntimeWarning: Mean of empty slice\n",
            "  mean = [np.nanmean(correct), np.nanmean(auc_roc), np.nanmean(auc_pr),tp, tn, fp, fn]\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/lib/_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
            "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mPCBP2_HepG2 \t Train Epoch: 4     avg.loss: 0.5452 Acc: 0.83%, AUC: nan lr: 0.006600\u001b[0m\n",
            "\u001b[1m\u001b[31mPCBP2_HepG2 \t Test  Epoch: 4     avg.loss: 0.4690 Acc: 0.86%, AUC: 0.9212 (0.9212)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mPCBP2_HepG2 \t Train Epoch: 5     avg.loss: 0.5268 Acc: 0.83%, AUC: 0.9132 lr: 0.008000\u001b[0m\n",
            "\u001b[1m\u001b[32mPCBP2_HepG2 \t Test  Epoch: 5     avg.loss: 0.5198 Acc: 0.82%, AUC: 0.9199 (0.9212)\u001b[0m\n",
            "PCBP2_HepG2 auc: 0.9212 acc: 0.8577\n",
            "Loading model: /content/drive/MyDrive/PrismNet_files/exp/prismnet/out/models/PCBP2_HepG2_PrismNet_pu_best.pth\n",
            "train: [0 1] [8002 4000]\n",
            "test: [0 1] [2000 1000]\n",
            "Test  set: 3000\n",
            "> eval PCBP2_HepG2 auc: 0.9212 acc: 0.8577\n",
            "Evaluation file: /content/drive/MyDrive/PrismNet_files/exp/prismnet/out/evals/PCBP2_HepG2_PrismNet_pu.metrics\n",
            "Prediction file: /content/drive/MyDrive/PrismNet_files/exp/prismnet/out/evals/PCBP2_HepG2_PrismNet_pu.probs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TIA1_Hela\n",
        "!python -u /content/drive/MyDrive/PrismNet_files/tools/main.py \\\n",
        "    --train --eval \\\n",
        "    --lr 0.001 \\\n",
        "    --data_dir /content/drive/MyDrive/PrismNet_files/data/clip_data/ \\\n",
        "    --p_name TIA1_Hela \\\n",
        "    --out_dir /content/drive/MyDrive/PrismNet_files/exp/prismnet \\\n",
        "    --exp_name prismnet \\\n",
        "    --batch_size 32 \\\n",
        "    --workers 2 \\\n",
        "    --nepochs 5 \\\n",
        "    --pos_weight 2 \\\n",
        "    --weight_decay 1e-6 \\\n",
        "    --early_stopping 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwJearIqTH0i",
        "outputId": "3ae7df5d-4d78-4ade-8c77-b4212c35eef9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='/content/drive/MyDrive/PrismNet_files/data/clip_data/', exp_name='prismnet', p_name='TIA1_Hela', out_dir='/content/drive/MyDrive/PrismNet_files/exp/prismnet', mode='pu', infer_file='', arch='PrismNet', lr_scheduler='warmup', lr=0.001, batch_size=32, nepochs=5, pos_weight=2, weight_decay=1e-06, early_stopping=20, load_best=False, eval=True, train=True, infer=False, infer_test=False, eval_test=False, saliency=False, saliency_img=False, har=False, tfboard=False, no_cuda=False, workers=2, log_interval=100, seed=1024)\n",
            "Network Arch: PrismNet\n",
            "===========================\n",
            "Total params: 58189\n",
            "Trainable params: 58189\n",
            "Non-trainable params: 0\n",
            "===========================\n",
            "train: [0 1] [8002 4000]\n",
            "test: [0 1] [2000 1000]\n",
            "train: [0 1] [8002 4000]\n",
            "test: [0 1] [2000 1000]\n",
            "Train set: 12002\n",
            "Test  set: 3000\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mTIA1_Hela \t Train Epoch: 1     avg.loss: 0.4673 Acc: 0.85%, AUC: 0.9322 lr: 0.002400\u001b[0m\n",
            "\u001b[1m\u001b[31mTIA1_Hela \t Test  Epoch: 1     avg.loss: 0.4304 Acc: 0.87%, AUC: 0.9455 (0.9455)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mTIA1_Hela \t Train Epoch: 2     avg.loss: 0.4233 Acc: 0.88%, AUC: 0.9452 lr: 0.003800\u001b[0m\n",
            "\u001b[1m\u001b[32mTIA1_Hela \t Test  Epoch: 2     avg.loss: 0.4246 Acc: 0.90%, AUC: 0.9434 (0.9455)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/PrismNet_files/prismnet/utils/metrics.py:169: RuntimeWarning: Mean of empty slice\n",
            "  mean = [np.nanmean(correct), np.nanmean(auc_roc), np.nanmean(auc_pr),tp, tn, fp, fn]\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/lib/_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
            "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mTIA1_Hela \t Train Epoch: 3     avg.loss: 0.4302 Acc: 0.88%, AUC: nan lr: 0.005200\u001b[0m\n",
            "\u001b[1m\u001b[31mTIA1_Hela \t Test  Epoch: 3     avg.loss: 0.3961 Acc: 0.89%, AUC: 0.9458 (0.9458)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/PrismNet_files/prismnet/utils/metrics.py:169: RuntimeWarning: Mean of empty slice\n",
            "  mean = [np.nanmean(correct), np.nanmean(auc_roc), np.nanmean(auc_pr),tp, tn, fp, fn]\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/lib/_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
            "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mTIA1_Hela \t Train Epoch: 4     avg.loss: 0.4225 Acc: 0.88%, AUC: nan lr: 0.006600\u001b[0m\n",
            "\u001b[1m\u001b[31mTIA1_Hela \t Test  Epoch: 4     avg.loss: 0.3937 Acc: 0.90%, AUC: 0.9483 (0.9483)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:204: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "\u001b[1m\u001b[32mTIA1_Hela \t Train Epoch: 5     avg.loss: 0.4029 Acc: 0.88%, AUC: 0.9520 lr: 0.008000\u001b[0m\n",
            "\u001b[1m\u001b[31mTIA1_Hela \t Test  Epoch: 5     avg.loss: 0.3971 Acc: 0.88%, AUC: 0.9511 (0.9511)\u001b[0m\n",
            "TIA1_Hela auc: 0.9511 acc: 0.8793\n",
            "Loading model: /content/drive/MyDrive/PrismNet_files/exp/prismnet/out/models/TIA1_Hela_PrismNet_pu_best.pth\n",
            "train: [0 1] [8002 4000]\n",
            "test: [0 1] [2000 1000]\n",
            "Test  set: 3000\n",
            "> eval TIA1_Hela auc: 0.9511 acc: 0.8793\n",
            "Evaluation file: /content/drive/MyDrive/PrismNet_files/exp/prismnet/out/evals/TIA1_Hela_PrismNet_pu.metrics\n",
            "Prediction file: /content/drive/MyDrive/PrismNet_files/exp/prismnet/out/evals/TIA1_Hela_PrismNet_pu.probs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# List all 6 proteins\n",
        "proteins = ['PCBP1_K562', 'SRSF9_HepG2', 'TRA2A_K562', 'HNRNPC_Hela', 'PCBP2_HepG2', 'TIA1_Hela']\n",
        "\n",
        "metrics_dir = '/content/drive/MyDrive/PrismNet_files/exp/prismnet/out/evals/'\n",
        "results = []\n",
        "\n",
        "for p in proteins:\n",
        "    metrics_file = f\"{metrics_dir}{p}_PrismNet_pu.metrics\"\n",
        "    try:\n",
        "        df = pd.read_csv(metrics_file, sep='\\t', header=None)\n",
        "        acc = df.iloc[0, 1]\n",
        "        auroc = df.iloc[0, 2]\n",
        "        tp, tn, fp, fn = df.iloc[0, 4], df.iloc[0, 5], df.iloc[0, 6], df.iloc[0, 7]\n",
        "\n",
        "        # F1 calculation\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        results.append({'Protein': p, 'AUROC': auroc, 'Accuracy': acc, 'F1': f1})\n",
        "    except Exception as e:\n",
        "        print(f\"Could not read metrics for {p}: {e}\")\n",
        "        results.append({'Protein': p, 'AUROC': None, 'Accuracy': None, 'F1': None})\n",
        "\n",
        "# Create summary DataFrame\n",
        "summary_df = pd.DataFrame(results)\n",
        "print(summary_df)\n",
        "\n",
        "# Compute averages\n",
        "auc_avg = summary_df['AUROC'].dropna().mean()\n",
        "acc_avg = summary_df['Accuracy'].dropna().mean()\n",
        "f1_avg = summary_df['F1'].dropna().mean()\n",
        "\n",
        "print(f\"\\nAverage AUROC: {auc_avg:.4f}\")\n",
        "print(f\"Average Accuracy: {acc_avg:.4f}\")\n",
        "print(f\"Average F1: {f1_avg:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umwLpPJcFEMN",
        "outputId": "bda1739e-6f9e-463a-cf26-33c53ce1da56"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Protein  AUROC  Accuracy        F1\n",
            "0   PCBP1_K562  0.902     0.840  0.750000\n",
            "1  SRSF9_HepG2  0.805     0.675  0.624037\n",
            "2   TRA2A_K562  0.874     0.808  0.689952\n",
            "3  HNRNPC_Hela  0.913     0.797  0.748760\n",
            "4  PCBP2_HepG2  0.921     0.858  0.795791\n",
            "5    TIA1_Hela  0.951     0.879  0.834097\n",
            "\n",
            "Average AUROC: 0.8943\n",
            "Average Accuracy: 0.8095\n",
            "Average F1: 0.7404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f-VPhrK5FEQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZnF-1z3vFER8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Exzl6mHWFETz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}